{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np # forlinear algebra\n",
    "import matplotlib.pyplot as plt #for plotting things\n",
    "import os\n",
    "from PIL import Image\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Keras Libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_491222/770385076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Keras Libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mainDIR = os.listdir('../input/chest_xray/chest_xray')\n",
    "print(mainDIR)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_folder= '../input/chest_xray/chest_xray/train/'\n",
    "val_folder = '../input/chest_xray/chest_xray/val/'\n",
    "test_folder = '../input/chest_xray/chest_xray/test/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train \n",
    "os.listdir(train_folder)\n",
    "train_n = train_folder+'NORMAL/'\n",
    "train_p = train_folder+'PNEUMONIA/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Normal pic \n",
    "print(len(os.listdir(train_n)))\n",
    "rand_norm= np.random.randint(0,len(os.listdir(train_n)))\n",
    "norm_pic = os.listdir(train_n)[rand_norm]\n",
    "print('normal picture title: ',norm_pic)\n",
    "\n",
    "norm_pic_address = train_n+norm_pic\n",
    "\n",
    "#Pneumonia\n",
    "rand_p = np.random.randint(0,len(os.listdir(train_p)))\n",
    "\n",
    "sic_pic =  os.listdir(train_p)[rand_norm]\n",
    "sic_address = train_p+sic_pic\n",
    "print('pneumonia picture title:', sic_pic)\n",
    "\n",
    "# Load the images\n",
    "norm_load = Image.open(norm_pic_address)\n",
    "sic_load = Image.open(sic_address)\n",
    "\n",
    "#Let's plt these images\n",
    "f = plt.figure(figsize= (10,6))\n",
    "a1 = f.add_subplot(1,2,1)\n",
    "img_plot = plt.imshow(norm_load)\n",
    "a1.set_title('Normal')\n",
    "\n",
    "a2 = f.add_subplot(1, 2, 2)\n",
    "img_plot = plt.imshow(sic_load)\n",
    "a2.set_title('Pneumonia')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# let's build the CNN model\n",
    "\n",
    "cnn = Sequential()\n",
    "\n",
    "#Convolution\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 3)))\n",
    "\n",
    "#Pooling\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# 2nd Convolution\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "\n",
    "# 2nd Pooling layer\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Flatten the layer\n",
    "cnn.add(Flatten())\n",
    "\n",
    "# Fully Connected Layers\n",
    "cnn.add(Dense(activation = 'relu', units = 128))\n",
    "cnn.add(Dense(activation = 'sigmoid', units = 1))\n",
    "\n",
    "# Compile the Neural network\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_of_test_samples = 600\n",
    "batch_size = 32"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fitting the CNN to the images\n",
    "# The function ImageDataGenerator augments your image by iterating through image as your CNN is getting ready to process that image\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)  #Image normalization.\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('../input/chest_xray/chest_xray/train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory('../input/chest_xray/chest_xray/val/',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('../input/chest_xray/chest_xray/test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cnn.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cnn_model = cnn.fit_generator(training_set,\n",
    "                         steps_per_epoch = 163,\n",
    "                         epochs = 1,\n",
    "                         validation_data = validation_generator,\n",
    "                         validation_steps = 624)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_accu = cnn.evaluate_generator(test_set,steps=624)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('The testing accuracy is :',test_accu[1]*100, '%')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Y_pred = cnn.predict_generator(test_set, 100)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "# confusion_matrix(validation_generator.classes, y_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "max(y_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Accuracy \n",
    "plt.plot(cnn_model.history['acc'])\n",
    "plt.plot(cnn_model.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training set', 'Validation set'], loc='upper left')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Loss \n",
    "\n",
    "plt.plot(cnn_model.history['val_loss'])\n",
    "plt.plot(cnn_model.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training set', 'Test set'], loc='upper left')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('pneumonia-ML': virtualenv)"
  },
  "interpreter": {
   "hash": "3d45f34991c5441a408525fe39163f1e5868ebb3dac78003d6154a3d7b4d01da"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}